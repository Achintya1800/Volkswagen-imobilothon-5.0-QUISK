# ðŸš— Volkswagen Intelligent Hazard Detection System

### ðŸ“˜ Overview
AI-driven hazard detection and feedback learning system for smart vehicles.  
Integrates **computer vision**, **sensor fusion**, and **edgeâ€“cloud intelligence** to detect and alert drivers about potholes, bumps, debris, or stalled vehicles.

---

## ðŸŒ Live Demo
**Streamlit App:** [https://achintya1800-volkswagen-imobilothon-5-0-streamlit-appapp-f5qiti.streamlit.app/](https://achintya1800-volkswagen-imobilothon-5-0-streamlit-appapp-f5qiti.streamlit.app/)

---

## ðŸ“ Dataset and Model Files Drive Link
**Link:** [https://drive.google.com/drive/folders/1PWQ2dsXSa79uncikRV6ATzlDeLciri_Q](https://drive.google.com/drive/folders/1PWQ2dsXSa79uncikRV6ATzlDeLciri_Q)

---

## ðŸ§  1ï¸. Architecture Overview
![System Architecture](./images/architecture_diagram.png)

ðŸŽ¥ **Volkswagen Project Full Demo**

https://github.com/user-attachments/assets/64cc82e8-a8d0-43d1-82a7-9cadba35879e


> ï¿½ *You can also watch the full demo on [YouTube](https://youtu.be/GqcZbpZZ1c0).*

---

## ðŸ—ºï¸ 2. Offline Map Preparation

ðŸŽ¯ **Objective:**  
Enable safe and optimized navigation by combining **real-time** and **offline hazard-aware routing**.

âš™ï¸ **Key Highlights:**  
- **Startâ€“End Input:** Driver selects source and destination (works online & offline).  
- **Smart Route Fetching:** Fetches the safest & most efficient route using preloaded hazard data.  
- **Hazard Overlay:** Displays potholes, bumps, and debris along the route using YOLO-based detection.  
- **Voice Alerts:** Real-time voice guidance warns the driver of upcoming hazards.  
- **Offline Mode:** Operates seamlessly with pre-fetched routes and hazard cache.  
- **Hazard Density Slider:** Allows users to simulate or adjust hazard visibility on the map.  

![Offline Map Preparation](./images/Driver.png)

---

## ðŸš— 3ï¸. Image Capture Rate Controller (AKS)

ðŸŽ¯ **Objective:**  
Optimize video processing by capturing only key frames through **Adaptive Keyframe Sampling (AKS)**.

ðŸ” **Overview:**  
- Monitors video stream, motion, and scene content in real time.  
- Skips redundant frames when the car is static or moving slowly.  
- Captures more frames during rapid motion or new object appearance.  
- Processes **only keyframes** to maintain efficiency without losing critical details.  

âš™ï¸ **Impact:**  
Reduces compute load and latency by **up to 60%**, while preserving essential scene information.

ðŸ“Š **Performance Summary**

| Scenario | Avg Speed | Keyframes Saved | Behavior |
|-----------|------------|------------------|-----------|
| ðŸš¦ City / Traffic | 0.18 km/h | 20.08% | Slow â†’ Frames skipped |
| ðŸ›£ï¸ Highway | 13.07 km/h | 23.82% | Fast â†’ More frames saved |


![AKS](./images/AKS.png)

---

## ðŸ§© 4ï¸. Composite Image Generation

Combines multiple camera feeds into a **single unified frame** using OpenCV.

ðŸ§  **Pipeline**
1. **Multiple Image Frames** â†’ Input from different cameras  
2. **Fisheye Distortion Correction** â†’ Removes lens curvature and fixes 180Â°+ distortion  
3. **Inverse Perspective Mapping (IPM)** â†’ Aligns ground plane and maintains consistent scale  
4. **Multi-Band Blending (Laplacian Pyramids)** â†’ Seamless merging, removes seams  
5. **Unified Frame** â†’ Final panoramic composite  

![Input](./images/composite.png)

---

## ðŸ§© 5ï¸. Image Quality Enhancement (DehazeNet)

Enhances **foggy, hazy, or low-light** frames using a **lightweight GAN-based AOD-Net** to restore clarity and boost detection accuracy.

**Key Points:**
- 5-layer CNN with skip connections  
- Fast, CPU-friendly, deployable on mobile  
- Formula: `clean = ReLU((x5 * x) - x5 + 1)`  
- Input â†’ RGB image | Output â†’ Dehazed RGB image  

ðŸŽ¯ **Goal:** Restore clear visuals for reliable vision-based detection.

ðŸ–¼ï¸ Before vs After Dehazing:  
![Dehaze Example](./images/dehaze.png)

---

## ðŸ§© 6ï¸. Feature Extractor
The **Feature Extractor** is the vision intelligence core of the system.  
It performs **multi-head visual analysis** to detect, segment, measure, and track road hazards with ego-motion compensation.

| Head | Task | Model |
|------|------|--------|
| 1 | Object Detection (Pothole, Bump, Debris) | YOLOv10 + DINOv3 Distillation |
| 2 | Segmentation (Pothole Size Estimation) | YOLOv8 (self-trained) |
| 3 | Depth & Severity Estimation | MiDaS-small |
| 4 | Road Mask (On-road or Pavement) | Fast-SCNN |
| 5 | Stalled Vehicle Tracking | YOLOv10 + SORT (Kalman Filter) + Affine RANSAC |

---

### ðŸ§© Head 1: Detection
- Detects **potholes, bumps, and debris** using **YOLOv10**.
- Enhanced via **DINOv3 â†’ YOLOv10 distillation**, transferring texture-rich features for better accuracy.
- Provides base bounding boxes for later modules.

![Head 1 â€“ Detection](./images/H1.png)

---

### ðŸ§© Head 2: Segmentation

ðŸŽ¯ **Goal**  
Detect and segment **pothole regions** using a **YOLOv8-Segmentation** model to obtain **pixel-level masks** that quantify the damaged road surface area.

**Model Summary**

| Parameter | Description |
|------------|--------------|
| **Input** | 640Ã—640 RGB road image |
| **Output** | Bounding box + Mask for each detected pothole |
| **Model File** | `YoloV8Segmented.pt` |

ðŸ§® **Formula**  
`Pothole Area = Î£(mask_pixels) Ã— (pixel_scale)^2`

ðŸ“Š **Performance Metrics**

| Metric | Value |
|---------|--------|
| Precision | 0.76 |
| Recall | 0.59 |
| mAP50 | 0.72 |
| mAP50â€“95 | 0.45 |
| Fitness | 0.878 |

![Head 2 â€“ Segmentation](./images/segmentation.png)

---

### ðŸ§© Head 3: Depth & Severity Estimation

**Overview**  
Estimates the **depth**, **width**, and **area** of detected potholes using **MiDaS v2.1 Small**.  
Each pothole is then classified as **Minor**, **Moderate**, or **Severe** based on **depthâ€“area thresholds**.

**Workflow**
1. Take **segmented pothole masks** from YOLOv8-Segmentation output.  
2. Generate a **relative depth map** using **MiDaS-small (256)**.  
3. Compute:
   - **Area** â†’ from mask pixels  
   - **Width / Height** â†’ from bounding box  
   - **Depth** â†’ mean depth in masked region  
4. Combine **depth and area** to classify severity.  

ðŸ§® **Formula for Apparent Size**
`S = f * X / Z`

**Where:**
- f = focal length  
- X = observed pixel width  
- Z = distance from camera  

ðŸ–¼ï¸ **Output Example**  
![Head 3 â€“ Depth Estimation](./images/midas.png)

---

### ðŸ§© Head 4: Road Mask

ðŸŽ¯ **Goal**  
Determine whether each detected object lies **on the drivable surface** or **off-road/pavement**.  
Helps filter false hazards and improves safety analytics.

âš™ï¸ **Architecture Overview**

| Head | Purpose | Model Used | Input | Output |
|------|----------|-------------|--------|---------|
| 1 | Road Segmentation | ðŸ§© Fast-SCNN (Cityscapes-trained) | RGB image | Binary road mask |
| 2 | Pothole Masking | ðŸŽ¯ YOLOv8-Seg (custom-trained) | RGB image | Pothole masks |
| 3 | Vehicle Segmentation | ðŸš— YOLOv11n-Seg (COCO-pretrained) | RGB image | Vehicle masks |

ðŸ§® **Computation**
`on_road_ratio = overlap_area / object_area`

ðŸ–¼ï¸ **Example Output**  
![Head 4 â€“ Road Mask](./images/mask.png)

---

### ðŸ§© Head 5: Stalled Vehicles Tracking
- Detects and tracks **stalled vehicles** using **YOLOv10 + SORT (Kalman Filter)**.  
- Compensates for **camera motion** using **Affine RANSAC** on background features.

ðŸ§® **Ego-Motion Compensation Formula:**
![Head 5 â€“ Formula](./images/stallformula.png)


[![Watch the Demo](./images/stalled.png)](https://drive.google.com/file/d/1Lp4UQRNKpWIADlHd_ZKrdra-IUGOxaDZ/view?usp=drive_link)
>

---

## âœ… 7ï¸. Fusion Engine

ðŸŽ¯ **Goal**  
Fuse outputs from all perception heads into one reliable **confidence score (C_final)** for final hazard decision.

âš™ï¸ **Workflow**
1. Collect outputs from all heads.  
2. Compute individual confidence scores.  
3. Apply **fusion rules** â€” Weighted, Multiplicative, or Rule-Based.  
4. Generate final **C_final** for verification and alert modules.

ðŸ§® **Individual Confidence Scores**

| Head | Metric | Formula |
|------|---------|----------|
| Detection | Class Ã— IoU | `C_detect = P_class Ã— IoU` |
| Segmentation | Mask ratio | `C_seg = Area_mask / Area_bbox` |
| Depth | Error decay | `exp(-depth_error / Ïƒ)` |
| Road | On-road penalty | `C_road = {1.0 if on_road, Î± if off_road}` |
| Tracking | Persistence | `C_track = min(track_age / T_stable, 1) Ã— (1 - miss_rate)` |


---

## ðŸ”’ 8ï¸. Privacy Blur

ðŸŽ¯ **Goal**  
Blur faces and license plates **on-device** before upload using **YOLOv8 + Gaussian Blur**.

âš™ï¸ **Workflow**
1. Frame input from Fusion Engine.  
2. Detect faces & plates using YOLOv8.  
3. Apply Gaussian blur using OpenCV.  
4. Forward anonymized output downstream.

ðŸ–¼ï¸ **Results**

| Face Blur | Number Plate Blur |
|------------|------------------|
| ![Face Blur](./images/blurred_privacy1.png) | ![Plate Blur](./images/blurred_privacy2.png) |



---

## ðŸ—£ï¸ 9ï¸. Voice-Based Verification

ðŸŽ¯ **Goal**  
Validate detected hazards through **trusted driver voice feedback** using a **verification popover interface**.

âš™ï¸ **Workflow**
1. Send hazard clip to trusted driver.  
2. Collect **Yes / No / Unsure** response.  
3. Apply **Speech-to-Text** + Bayesian trust update.  
4. Confirmed hazards are uploaded; rejected ones discarded.

ðŸ§® **Confidence Adjustment**
`C_verified = C_final Ã— Î²`  
(`Î² = 1.2` if verified, `0.5` if unverified)

ðŸ§® **Trust Update**
`Trust_new = Trust_prev + Î· Ã— (Verification_result - Expected)`



---

## ðŸ§  10. Feedback Learning (Federated PPO)

ðŸŽ¯ **Goal / Motto**  
â€œEvery vehicle learns â€” the fleet gets smarter.â€  
Uses **federated PPO learning** to improve detection without sharing raw data.

âš™ï¸ **Process**
1. Vehicles train locally.  
2. Send model updates (not data) to server.  
3. Server aggregates via PPO.  
4. Global model redistributed â†’ continuous improvement.
**Example Output**  
![Feedback](./images/Feedback.png)
---

## âš¡ 1ï¸1ï¸. Alert System

ðŸŽ¯ **Goal**
Ensure reliable, **non-redundant hazard uploads** from drivers to the server â€” even offline.

âš™ï¸ **Workflow**
1. **Connectivity Check**
   - âœ… Internet â†’ Send via **MQTT**  
   - âŒ Offline â†’ Store in local cache till connectivity regained
2. **Server Receives Data**
3. **Clustering (Haversine Formula)**
   - Merge nearby hazards to prevent duplicates.

ðŸ§® **Formula**
`d = 2R Ã— arcsin(âˆša)`  
`a = sinÂ²(Î”lat/2) + cos(latâ‚) Ã— cos(latâ‚‚) Ã— sinÂ²(Î”lon/2)`


---

## ðŸš— Kivy App â€“ V2X Hazard Alert Simulation (Wi-Fi Direct Prototype)

ðŸ“˜ **Overview**
This project simulates **V2X-based hazard alert communication** between nearby vehicles using **Wi-Fi Direct (P2P)** instead of DSRC, due to unavailable hardware.  
Itâ€™s part of the **hazard detection and alerting pipeline**, where detected road anomalies (like potholes, debris, or bumps) are broadcast to nearby drivers.  



ðŸ§© **Key Features**
- **Cross-Platform Kivy App:** Built with Kivy + Python for Android compatibility.  
- **Fallback GPS Coordinates:** Uses hardcoded coordinates (mock location) as GPS data is considered to be available in-car.  
- Instead of DSRC (V2X), hazard alerts are **broadcast to nearby devices via Wi-Fi Direct (P2P)** for now.  
This allows testing **V2X-like communication** and **Geofencing** without requiring specialized hardware.


| SENDER | RECEIVER |
|------------|------------------|
| ![sender](./images/v2x.png) | ![Plate Blur](./images/v2x2.png) |

![v2ximage](./images/v2ximage.jpg)



## ðŸ§© 1ï¸3. Tech Stack

### ðŸ¤– **AI / ML Frameworks**
- **YOLOv10s** â†’ Object detection for potholes, debris, stalled vehicles  
- **YOLOv8-Seg** â†’ Pixel-level segmentation for pothole shape & area estimation  
- **MiDaS-small v2.1** â†’ Depth & severity estimation  
- **Fast-SCNN** â†’ Lightweight road mask segmentation (drivable area classification)  
- **DINOv3 Distillation** â†’ Feature-rich representation transfer to YOLOv10  
- **PPO (Proximal Policy Optimization)** â†’ Federated feedback learning algorithm  
- **AOD-Net & DehazeNet** â†’ Low-light & haze restoration for image clarity  
- **SORT** â†’ Object tracking with Kalman Filter + IoU Matching  




---

### â˜ï¸ **Cloud & Communication**
- **MQTT** â†’ Data transfer between vehicle â†’ cloud â†’ app  
- **V2X Communication (DSRC, Geofencing)** â†’ Peer-to-peer vehicle alerts  
- **Haversine Clustering** â†’ In-server deduplication of hazard reports  

---

### ðŸ”’ **Security & Privacy**
- **YOLOv8 Face + Plate Detector** â†’ Privacy blur before upload  
- **SSL / TLS** â†’ Secure data transmission  
- **Tokenized Session Handling** â†’ Avoids redundant hazard submissions  

---

### ðŸ§­ **Mapping & Navigation**
- **OSRM (OpenStreetMap) APIs** â†’ Map rendering & hazard overlay  
- **Leaflet.js / Mapbox** â†’ Real-time road visualization  
- **Offline Tile Caching** â†’ Hazard-aware route navigation when offline  






---

ðŸ§  **Summary:**  
The pipeline spans **edge AI, federated learning, and cloud analytics**, ensuring reliability, privacy, and real-time hazard awareness from detection â†’ verification â†’ alert dissemination.


---

##  Impact
> Enhances road safety by detecting and verifying real-world hazards in real time â€” even in fog, low-light, or offline conditions.
